# anyuzhangpuzzle_2018


## Table of Contents
1. [Understanding the challenge](README.md#understanding-the-challenge)
2. [Implementation details](README.md#implementation-details)
3. [Test Results](README.md#test-results)
4. [My input files](README.md#my-input-files)
5. [My output file](README.md#my-output-file)

## Understanding the challenge


## Implementation details



## Test of Format 

Pass

The result generated by my seesionization.py is exactly same as the file saved in the test output.
    

## My input files
### Log.csv
From the website SEC weblogs I can access to a lot of datasets, I picked sample datasets at one day from 2003 to 2017. The datasets varied a lot from 106kB to 2.78GB, which is beneficial to checking the performance of my sessionization.py on small and large datasets. 

But the git hub only allow me upload files smaller than 25 MB. So what you can access in tests folder are just small datasets.
### inactivity_period.txt


## Optimization of sessionization.py 

From the details of challange I know the duration is a important value to check if an IP is in a session of a single web page document request. The value will range from 1 to 86,400 (i.e., one second to 24 hours)

In the given test example, the duration time is 2 seconds. By increasing the duration time : 2 seconds , 3seconds and 100 seconds, the computing time of output file increased also. 

With a large dataset in 2017, which size is 2.78GB, the computating time is as long as more than 20 mins in the first version of my sessionization.py. It is too long to be a applicable program. So I made changes like following:




    For checking the performence of optimized sessionization method, I used the 455.9MB dataset in 06/29/2011 with 100s duration time. 
    original                          optimized 
    real	6m3.742s                  real	3m17.475s
    user	6m0.968s                  real	3m17.475s
    sys	0m1.282s                  sys	0m1.084s



